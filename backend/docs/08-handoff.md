# Human Handoff System

When the AI's confidence drops below a threshold, or a policy rule is matched, or the customer explicitly asks for a human, the handoff system takes over.

## Triggers

| Trigger | Source | Condition |
|---|---|---|
| `LOW_CONFIDENCE` | Confidence scorer | `composite < agent.handoffThreshold` |
| `ANGER_DETECTED` | Confidence scorer | `emotional < 0.25` (highly distressed) |
| `EXPLICIT_REQUEST` | Message classifier | Phrases like "speak to a human", "real person", "agent please" |
| `POLICY_RULE` | Routing policy | The agent's system prompt instructs handoff under certain conditions and GPT decides to |
| `BUSINESS_HOURS` | Business hours check | Message received outside configured hours |

---

## Handoff Decision in Pipeline

```ts
// In pipeline.service.ts, after scoring:
async function decideHandoff(
  agent: Agent,
  confidence: ConfidenceComponents & { composite: number },
  userMessage: string,
): Promise<boolean> {
  if (!agent.handoffEnabled) return false;

  // Explicit request detection (fast, regex-based)
  if (isExplicitHandoffRequest(userMessage)) return true;

  // Anger threshold (overrides composite)
  if (confidence.emotional < 0.25) return true;

  // Low composite confidence
  if (confidence.composite < agent.handoffThreshold) return true;

  return false;
}

function isExplicitHandoffRequest(message: string): boolean {
  const patterns = [
    /speak.*to.*(?:a |an )?(human|person|agent|representative|rep)/i,
    /talk.*to.*(?:a |an )?(human|person|agent|representative|rep)/i,
    /(?:real|actual|live)\s+(person|human|agent)/i,
    /connect.*(?:human|agent)/i,
    /escalate/i,
    /transfer.*(?:me|call)/i,
  ];
  return patterns.some(p => p.test(message));
}
```

---

## Handoff Execution

```ts
async function triggerHandoff(params: {
  conversation: Conversation;
  agent: Agent;
  trigger: HandoffTrigger;
  confidence?: number;
  userMessage: string;
}): Promise<void> {
  const { conversation, agent, trigger, confidence, userMessage } = params;

  // 1. Generate summary of conversation so far
  const summary = await generateHandoffSummary(conversation.id, userMessage);

  // 2. Create Handoff record
  const handoff = await prisma.handoff.create({
    data: {
      conversationId: conversation.id,
      trigger,
      confidence,
      summary,
      destination: agent.handoffDest,
    },
  });

  // 3. Update conversation status
  await prisma.conversation.update({
    where: { id: conversation.id },
    data: { status: 'HANDED_OFF' },
  });

  // 4. Send customer a message about the handoff
  const handoffMsg = buildHandoffMessage(trigger, agent.handoffDest);
  await prisma.message.create({
    data: {
      conversationId: conversation.id,
      role: 'SYSTEM',
      content: handoffMsg,
    },
  });

  // 5. Route to destination helpdesk
  await routeToDestination(agent, conversation, handoff, summary);

  // 6. Emit realtime event to dashboard
  await socketService.emitToWorkspace(conversation.workspaceId, 'handoff_triggered', {
    conversationId: conversation.id,
    handoffId: handoff.id,
    trigger,
  });
}
```

---

## Handoff Summary Generation

The summary is generated by GPT-4o-mini (cheap + fast) from the conversation history:

```ts
async function generateHandoffSummary(
  conversationId: string,
  lastMessage: string
): Promise<string> {
  const messages = await prisma.message.findMany({
    where: { conversationId },
    orderBy: { createdAt: 'asc' },
    take: 20,
  });

  const transcript = messages
    .map(m => `${m.role}: ${m.content}`)
    .join('\n');

  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [
      {
        role: 'system',
        content: `Summarize this customer support conversation in 3-5 bullet points. Include:
- Main issue/request
- What was tried or said so far
- Customer's current sentiment
- Why handoff was triggered
Be concise. Write for a human agent about to take over.`,
      },
      { role: 'user', content: `Transcript:\n${transcript}\n\nLast message: ${lastMessage}` },
    ],
    max_tokens: 300,
    temperature: 0.1,
  });

  return response.choices[0].message.content ?? 'No summary available.';
}
```

---

## Routing to Helpdesks

### Zendesk

```ts
async function routeToZendesk(
  creds: ZendeskCreds,
  conversation: Conversation,
  summary: string
): Promise<string> {
  const response = await fetch(`https://${creds.subdomain}.zendesk.com/api/v2/tickets.json`, {
    method: 'POST',
    headers: {
      Authorization: `Basic ${Buffer.from(`${creds.email}/token:${creds.apiToken}`).toString('base64')}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      ticket: {
        subject: `AI Handoff: ${conversation.customerId}`,
        comment: { body: summary },
        requester: { name: conversation.customerName ?? conversation.customerId },
        tags: ['axon-ai-handoff', conversation.channelType.toLowerCase()],
        priority: 'normal',
      },
    }),
  });

  const data = await response.json();
  return String(data.ticket.id);  // external ticket ID
}
```

### Freshdesk

```ts
async function routeToFreshdesk(
  creds: FreshdeskCreds,
  conversation: Conversation,
  summary: string
): Promise<string> {
  const response = await fetch(`https://${creds.domain}.freshdesk.com/api/v2/tickets`, {
    method: 'POST',
    headers: {
      Authorization: `Basic ${Buffer.from(`${creds.apiKey}:X`).toString('base64')}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      subject: `AI Handoff: ${conversation.customerId}`,
      description: summary,
      email: conversation.customerId.includes('@') ? conversation.customerId : undefined,
      phone: conversation.customerId.includes('+') ? conversation.customerId : undefined,
      priority: 2, // Medium
      status: 2,   // Open
      tags: ['axon-ai'],
    }),
  });

  const data = await response.json();
  return String(data.id);
}
```

### Email Queue

When no helpdesk is configured, send summary to the workspace admin email:

```ts
async function routeToEmailQueue(
  workspace: Workspace,
  conversation: Conversation,
  summary: string
): Promise<void> {
  await resend.emails.send({
    from: env.RESEND_FROM,
    to: workspace.adminEmail,
    subject: `[Handoff Required] Customer ${conversation.customerId}`,
    html: `
      <h2>A customer needs human assistance</h2>
      <p><strong>Channel:</strong> ${conversation.channelType}</p>
      <p><strong>Customer:</strong> ${conversation.customerId}</p>
      <h3>Summary</h3>
      <pre>${summary}</pre>
      <p><a href="${env.FRONTEND_URL}/dashboard/conversations/${conversation.id}">View Conversation</a></p>
    `,
  });
}
```

---

## Customer-Facing Handoff Messages

```ts
function buildHandoffMessage(trigger: HandoffTrigger, dest: HandoffDest): string {
  const destText = {
    ZENDESK: 'our support team',
    FRESHDESK: 'our support team',
    GORGIAS: 'our support team',
    EMAIL_QUEUE: 'a team member via email',
    NONE: 'a human agent',
    LIVE_AGENT: 'a live agent',
  }[dest];

  switch (trigger) {
    case 'EXPLICIT_REQUEST':
      return `Of course! I'm connecting you with ${destText} now. They'll be with you shortly.`;
    case 'LOW_CONFIDENCE':
      return `This seems like something ${destText} can better help you with. I've sent them a summary of our conversation.`;
    case 'ANGER_DETECTED':
      return `I'm sorry for the frustration. I'm connecting you with ${destText} right away.`;
    case 'BUSINESS_HOURS':
      return `I'm currently outside of business hours. I've created a ticket and ${destText} will follow up with you.`;
    default:
      return `I'm passing you over to ${destText} who can help you further.`;
  }
}
```

---

## Resolving a Handoff

When a human agent resolves the issue, they can mark the handoff as resolved and add a learning note:

```
PATCH /v1/handoffs/:id
Body: { "resolvedAt": "2026-02-18T12:00:00Z", "learningNote": "Customer wanted expedited shipping, agent gave 20% off." }
```

The learning note is stored for future fine-tuning and prompt improvement. It's not used in the AI pipeline yet (v1 scope), but can be surfaced in the analytics page.

---

## Conversation Re-Opening

After a handoff is resolved, the conversation status can be set back to `OPEN`, allowing the AI to handle future messages from the same customer again:

```
PATCH /v1/conversations/:id
Body: { "status": "OPEN" }
```
